{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ccbddc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as Plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2746609a",
   "metadata": {},
   "source": [
    "# get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "012c8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:\\computer science\\ml by krish naik\\Classified Data\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22bcde38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.162073</td>\n",
       "      <td>0.567946</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.780862</td>\n",
       "      <td>0.352608</td>\n",
       "      <td>0.759697</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>1.231409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.635632</td>\n",
       "      <td>1.003722</td>\n",
       "      <td>0.535342</td>\n",
       "      <td>0.825645</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>0.648450</td>\n",
       "      <td>0.675334</td>\n",
       "      <td>1.013546</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>1.492702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.721360</td>\n",
       "      <td>1.201493</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>1.526629</td>\n",
       "      <td>0.720781</td>\n",
       "      <td>1.626351</td>\n",
       "      <td>1.154483</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>1.285597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.234204</td>\n",
       "      <td>1.386726</td>\n",
       "      <td>0.653046</td>\n",
       "      <td>0.825624</td>\n",
       "      <td>1.142504</td>\n",
       "      <td>0.875128</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>1.380003</td>\n",
       "      <td>1.522692</td>\n",
       "      <td>1.153093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.279491</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.627280</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>1.232537</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>1.115596</td>\n",
       "      <td>0.646691</td>\n",
       "      <td>1.463812</td>\n",
       "      <td>1.419167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.010953</td>\n",
       "      <td>1.034006</td>\n",
       "      <td>0.853116</td>\n",
       "      <td>0.622460</td>\n",
       "      <td>1.036610</td>\n",
       "      <td>0.586240</td>\n",
       "      <td>0.746811</td>\n",
       "      <td>0.319752</td>\n",
       "      <td>1.117340</td>\n",
       "      <td>1.348517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.575529</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>0.941835</td>\n",
       "      <td>0.792882</td>\n",
       "      <td>1.414277</td>\n",
       "      <td>1.269540</td>\n",
       "      <td>1.055928</td>\n",
       "      <td>0.713193</td>\n",
       "      <td>0.958684</td>\n",
       "      <td>1.663489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.135470</td>\n",
       "      <td>0.982462</td>\n",
       "      <td>0.781905</td>\n",
       "      <td>0.916738</td>\n",
       "      <td>0.901031</td>\n",
       "      <td>0.884738</td>\n",
       "      <td>0.386802</td>\n",
       "      <td>0.389584</td>\n",
       "      <td>0.919191</td>\n",
       "      <td>1.385504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.084894</td>\n",
       "      <td>0.861769</td>\n",
       "      <td>0.407158</td>\n",
       "      <td>0.665696</td>\n",
       "      <td>1.608612</td>\n",
       "      <td>0.943859</td>\n",
       "      <td>0.855806</td>\n",
       "      <td>1.061338</td>\n",
       "      <td>1.277456</td>\n",
       "      <td>1.188063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.837460</td>\n",
       "      <td>0.961184</td>\n",
       "      <td>0.417006</td>\n",
       "      <td>0.799784</td>\n",
       "      <td>0.934399</td>\n",
       "      <td>0.424762</td>\n",
       "      <td>0.778234</td>\n",
       "      <td>0.907962</td>\n",
       "      <td>1.257190</td>\n",
       "      <td>1.364837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0    0.913917  1.162073  0.567946  0.755464  0.780862  0.352608  0.759697   \n",
       "1    0.635632  1.003722  0.535342  0.825645  0.924109  0.648450  0.675334   \n",
       "2    0.721360  1.201493  0.921990  0.855595  1.526629  0.720781  1.626351   \n",
       "3    1.234204  1.386726  0.653046  0.825624  1.142504  0.875128  1.409708   \n",
       "4    1.279491  0.949750  0.627280  0.668976  1.232537  0.703727  1.115596   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  1.010953  1.034006  0.853116  0.622460  1.036610  0.586240  0.746811   \n",
       "996  0.575529  0.955786  0.941835  0.792882  1.414277  1.269540  1.055928   \n",
       "997  1.135470  0.982462  0.781905  0.916738  0.901031  0.884738  0.386802   \n",
       "998  1.084894  0.861769  0.407158  0.665696  1.608612  0.943859  0.855806   \n",
       "999  0.837460  0.961184  0.417006  0.799784  0.934399  0.424762  0.778234   \n",
       "\n",
       "          PJF       HQE       NXJ  TARGET CLASS  \n",
       "0    0.643798  0.879422  1.231409             1  \n",
       "1    1.013546  0.621552  1.492702             0  \n",
       "2    1.154483  0.957877  1.285597             0  \n",
       "3    1.380003  1.522692  1.153093             1  \n",
       "4    0.646691  1.463812  1.419167             1  \n",
       "..        ...       ...       ...           ...  \n",
       "995  0.319752  1.117340  1.348517             1  \n",
       "996  0.713193  0.958684  1.663489             0  \n",
       "997  0.389584  0.919191  1.385504             1  \n",
       "998  1.061338  1.277456  1.188063             1  \n",
       "999  0.907962  1.257190  1.364837             1  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da640ead",
   "metadata": {},
   "source": [
    "# standardize the variable"
   ]
  },
  {
   "cell_type": "raw",
   "id": "630fe825",
   "metadata": {},
   "source": [
    "Because the KNN classifier predicts the class of a given test observation by identifying the observations that are nearest to it, the scale of the variables matters. Any variables that are on a large scale will have a much larger effect on the distance between the observations, and hence on the KNN classifier, than variables that are on a small scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd0a4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb7c0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49e7b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features=scaler.fit_transform(df.drop('TARGET CLASS',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b3b19fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12354188,  0.18590747, -0.91343069, ..., -1.48236813,\n",
       "        -0.9497194 , -0.64331425],\n",
       "       [-1.08483602, -0.43034845, -1.02531333, ..., -0.20224031,\n",
       "        -1.82805088,  0.63675862],\n",
       "       [-0.78870217,  0.33931821,  0.30151137, ...,  0.28570652,\n",
       "        -0.68249379, -0.37784986],\n",
       "       ...,\n",
       "       [ 0.64177714, -0.51308341, -0.17920486, ..., -2.36249443,\n",
       "        -0.81426092,  0.11159651],\n",
       "       [ 0.46707241, -0.98278576, -1.46519359, ..., -0.03677699,\n",
       "         0.40602453, -0.85567   ],\n",
       "       [-0.38765353, -0.59589427, -1.4313981 , ..., -0.56778932,\n",
       "         0.3369971 ,  0.01034996]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2587f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat=pd.DataFrame(scaled_features,columns=df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19df8002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123542</td>\n",
       "      <td>0.185907</td>\n",
       "      <td>-0.913431</td>\n",
       "      <td>0.319629</td>\n",
       "      <td>-1.033637</td>\n",
       "      <td>-2.308375</td>\n",
       "      <td>-0.798951</td>\n",
       "      <td>-1.482368</td>\n",
       "      <td>-0.949719</td>\n",
       "      <td>-0.643314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.084836</td>\n",
       "      <td>-0.430348</td>\n",
       "      <td>-1.025313</td>\n",
       "      <td>0.625388</td>\n",
       "      <td>-0.444847</td>\n",
       "      <td>-1.152706</td>\n",
       "      <td>-1.129797</td>\n",
       "      <td>-0.202240</td>\n",
       "      <td>-1.828051</td>\n",
       "      <td>0.636759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.788702</td>\n",
       "      <td>0.339318</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.755873</td>\n",
       "      <td>2.031693</td>\n",
       "      <td>-0.870156</td>\n",
       "      <td>2.599818</td>\n",
       "      <td>0.285707</td>\n",
       "      <td>-0.682494</td>\n",
       "      <td>-0.377850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.982841</td>\n",
       "      <td>1.060193</td>\n",
       "      <td>-0.621399</td>\n",
       "      <td>0.625299</td>\n",
       "      <td>0.452820</td>\n",
       "      <td>-0.267220</td>\n",
       "      <td>1.750208</td>\n",
       "      <td>1.066491</td>\n",
       "      <td>1.241325</td>\n",
       "      <td>-1.026987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.139275</td>\n",
       "      <td>-0.640392</td>\n",
       "      <td>-0.709819</td>\n",
       "      <td>-0.057175</td>\n",
       "      <td>0.822886</td>\n",
       "      <td>-0.936773</td>\n",
       "      <td>0.596782</td>\n",
       "      <td>-1.472352</td>\n",
       "      <td>1.040772</td>\n",
       "      <td>0.276510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.211653</td>\n",
       "      <td>-0.312490</td>\n",
       "      <td>0.065163</td>\n",
       "      <td>-0.259834</td>\n",
       "      <td>0.017567</td>\n",
       "      <td>-1.395721</td>\n",
       "      <td>-0.849486</td>\n",
       "      <td>-2.604264</td>\n",
       "      <td>-0.139347</td>\n",
       "      <td>-0.069602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.292453</td>\n",
       "      <td>-0.616901</td>\n",
       "      <td>0.369613</td>\n",
       "      <td>0.482648</td>\n",
       "      <td>1.569891</td>\n",
       "      <td>1.273495</td>\n",
       "      <td>0.362784</td>\n",
       "      <td>-1.242110</td>\n",
       "      <td>-0.679746</td>\n",
       "      <td>1.473448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.641777</td>\n",
       "      <td>-0.513083</td>\n",
       "      <td>-0.179205</td>\n",
       "      <td>1.022255</td>\n",
       "      <td>-0.539703</td>\n",
       "      <td>-0.229680</td>\n",
       "      <td>-2.261339</td>\n",
       "      <td>-2.362494</td>\n",
       "      <td>-0.814261</td>\n",
       "      <td>0.111597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.467072</td>\n",
       "      <td>-0.982786</td>\n",
       "      <td>-1.465194</td>\n",
       "      <td>-0.071465</td>\n",
       "      <td>2.368666</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>-0.422041</td>\n",
       "      <td>-0.036777</td>\n",
       "      <td>0.406025</td>\n",
       "      <td>-0.855670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.387654</td>\n",
       "      <td>-0.595894</td>\n",
       "      <td>-1.431398</td>\n",
       "      <td>0.512722</td>\n",
       "      <td>-0.402552</td>\n",
       "      <td>-2.026512</td>\n",
       "      <td>-0.726253</td>\n",
       "      <td>-0.567789</td>\n",
       "      <td>0.336997</td>\n",
       "      <td>0.010350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0   -0.123542  0.185907 -0.913431  0.319629 -1.033637 -2.308375 -0.798951   \n",
       "1   -1.084836 -0.430348 -1.025313  0.625388 -0.444847 -1.152706 -1.129797   \n",
       "2   -0.788702  0.339318  0.301511  0.755873  2.031693 -0.870156  2.599818   \n",
       "3    0.982841  1.060193 -0.621399  0.625299  0.452820 -0.267220  1.750208   \n",
       "4    1.139275 -0.640392 -0.709819 -0.057175  0.822886 -0.936773  0.596782   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.211653 -0.312490  0.065163 -0.259834  0.017567 -1.395721 -0.849486   \n",
       "996 -1.292453 -0.616901  0.369613  0.482648  1.569891  1.273495  0.362784   \n",
       "997  0.641777 -0.513083 -0.179205  1.022255 -0.539703 -0.229680 -2.261339   \n",
       "998  0.467072 -0.982786 -1.465194 -0.071465  2.368666  0.001269 -0.422041   \n",
       "999 -0.387654 -0.595894 -1.431398  0.512722 -0.402552 -2.026512 -0.726253   \n",
       "\n",
       "          PJF       HQE       NXJ  \n",
       "0   -1.482368 -0.949719 -0.643314  \n",
       "1   -0.202240 -1.828051  0.636759  \n",
       "2    0.285707 -0.682494 -0.377850  \n",
       "3    1.066491  1.241325 -1.026987  \n",
       "4   -1.472352  1.040772  0.276510  \n",
       "..        ...       ...       ...  \n",
       "995 -2.604264 -0.139347 -0.069602  \n",
       "996 -1.242110 -0.679746  1.473448  \n",
       "997 -2.362494 -0.814261  0.111597  \n",
       "998 -0.036777  0.406025 -0.855670  \n",
       "999 -0.567789  0.336997  0.010350  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263ed92e",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07a22ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5196f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(scaled_features,df['TARGET CLASS'],test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99cb6b",
   "metadata": {},
   "source": [
    "# Using KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1aabe6",
   "metadata": {},
   "source": [
    "we are trying to come up with a model to predict whether someone will TARGET CLASS or not. We'll start with k=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "333af59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42df897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1cdf536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9dae18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "765fd31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a5d9f7",
   "metadata": {},
   "source": [
    "# Prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cdea736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "863f497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[121  20]\n",
      " [ 13 146]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74202a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       141\n",
      "           1       0.88      0.92      0.90       159\n",
      "\n",
      "    accuracy                           0.89       300\n",
      "   macro avg       0.89      0.89      0.89       300\n",
      "weighted avg       0.89      0.89      0.89       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d068ac4",
   "metadata": {},
   "source": [
    "# choosing a k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "133c717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate=[]\n",
    "\n",
    "for i in range(1,40):\n",
    "    knn=KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i=knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i!=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79838e98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m40\u001b[39m),error_rate,color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdashed\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m          markerfacecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, markersize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError Rate vs. K Value\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0450800f",
   "metadata": {},
   "source": [
    "check at what k value we get minimum error and then find the classification report at that k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a6b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
